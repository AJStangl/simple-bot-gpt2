{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install  simpletransformers==0.63.3  > /dev/null\n",
    "!git clone https://github.com/Xirider/finetune-gpt2xl.git && chmod -R 777 finetune-gpt2xl/ && cd finetune-gpt2xl && pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def has_valid_line(input_line: str) -> bool:\n",
    "    bad_words_found = []\n",
    "    black_list = [\"[removed]\", \"[deleted]\"]\n",
    "    for word in black_list:\n",
    "        if input_line.lower().__contains__(word.lower()):\n",
    "            print(f\":: Line contains word {word}... Skipping\")\n",
    "            bad_words_found.append(input_line)\n",
    "\n",
    "    return len(bad_words_found) == 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import pandas\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "training_data_path = \"/content/drive/MyDrive/RawData/daya/Yuli-Ban-training.csv\"\n",
    "\n",
    "df = pandas.read_csv(training_data_path)\n",
    "\n",
    "conversations = list(df['TrainingString'])\n",
    "\n",
    "valid_lines = []\n",
    "for line in conversations:\n",
    "    if has_valid_line(line):\n",
    "        valid_lines.append(line)\n",
    "\n",
    "generator = torch.Generator()\n",
    "\n",
    "generator.manual_seed(0)\n",
    "\n",
    "train_size = int(0.9 * len(conversations))\n",
    "\n",
    "train_dataset_file, eval_dataset_file = random_split(list(valid_lines), [train_size, len(valid_lines) - train_size], generator=generator)\n",
    "\n",
    "print(f\"Train: {len(train_dataset_file)}\")\n",
    "print(f\"Eval: {len(eval_dataset_file)}\")\n",
    "print(f\"Total: {len(train_dataset_file)  + len(eval_dataset_file)}\")\n",
    "\n",
    "# Note: Something is still fucked up with this. It sort of works but if you look at the number of samples the trainer receives it does not report the total as printed above...\n",
    "# I think to maintain parody we need to use .txt files, and it appears like the implementation takes about anything valid...\n",
    "with open('/content/finetune-gpt2xl/train.csv', mode='w', encoding='utf-8') as csv_file:\n",
    "    fieldnames = ['text']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for line in train_dataset_file:\n",
    "        foo = repr(line)[1:-1] + \"<|endoftext|>\" + \"\\n\"\n",
    "        writer.writerow({'text': foo})\n",
    "\n",
    "with open('/content/finetune-gpt2xl/validation.csv', mode='w', encoding='utf-8') as csv_file:\n",
    "    fieldnames = ['text']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for line in eval_dataset_file:\n",
    "        foo = repr(line)[1:-1] + \"<|endoftext|>\" + \"\\n\" # Not sure if I need to scrub it like this but whatever, seems like it works...\n",
    "        writer.writerow({'text': foo})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!cd finetune-gpt2xl && deepspeed --num_gpus=1 run_clm.py --deepspeed ds_config.json --model_name_or_path gpt2-xl --train_file train.csv --validation_file validation.csv --do_train --do_eval --fp16 --overwrite_cache --evaluation_strategy=\"steps\" --output_dir finetuned --eval_steps 200 --num_train_epochs 6 --gradient_accumulation_steps 2 --per_device_train_batch_size 8 --learning_rate 1e-4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!cd finetune-gpt2xl && python run_generation.py --model_type=gpt2 --model_name_or_path=finetuned --length 200"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def capture_tag(test_string: str, expected_tag: str):\n",
    "    regex = r\"\\<\\|(.*)\\|\\>\"\n",
    "\n",
    "    matches = re.finditer(regex, test_string, re.MULTILINE)\n",
    "\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "\n",
    "        print (\"Match {matchNum} was found at {start}-{end}: {match}\".format(matchNum = matchNum, start = match.start(), end = match.end(), match = match.group()))\n",
    "\n",
    "        if match.group() == expected_tag:\n",
    "            return_string = test_string.replace(match.group(), \"\")\n",
    "            return return_string\n",
    "\n",
    "        for groupNum in range(0, len(match.groups())):\n",
    "            groupNum = groupNum + 1\n",
    "\n",
    "            print (\"Group {groupNum} found at {start}-{end}: {group}\".format(groupNum = groupNum, start = match.start(groupNum), end = match.end(groupNum), group = match.group(groupNum)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from simpletransformers.language_generation import LanguageGenerationModel, LanguageGenerationArgs\n",
    "\n",
    "text_model_generator = LanguageGenerationModel(\"gpt2\",  f\"/content/finetune-gpt2xl/finetuned\", args = {\n",
    "\t\t'max_length': 1000,\n",
    "\t\t'num_return_sequences': 1,\n",
    "\t\t'repetition_penalty': 1.01,\n",
    "\t\t'stop_token': '<|endoftext|>',\n",
    "\t\t'temperature': 0.8,\n",
    "\t\t'top_k': 40,\n",
    "\t}, use_cuda=True)\n",
    "\n",
    "print(\"It's going to be sad day when it learns to properly spell.  I feel like this era is a fleeting moment in AI history.  We must cherish it.\")\n",
    "prompt = \"<|soss r/dalle2|><|sot|>Detailed scientific diagram depicting the anatomy of a tomato, full colour, realistic<|sost|>https://i.imgur.com/7adBOXn.jpg<|sor u/AsterJ|>It's going to be sad day when it learns to properly spell.  I feel like this era is a fleeting moment in AI history.  We must cherish it.<|eor|><|sor|>\"\n",
    "\n",
    "import re\n",
    "regex = r\"\\<\\|(.*)\\|\\>\"\n",
    "\n",
    "\n",
    "reply = None\n",
    "refresh_args = {\n",
    "\t\t'max_length': 1000,\n",
    "\t\t'num_return_sequences': 1,\n",
    "\t\t'repetition_penalty': 1.01,\n",
    "\t\t'stop_token': '<|endoftext|>',\n",
    "\t\t'temperature': 0.8,\n",
    "\t\t'top_k': 40,\n",
    "\t}\n",
    "while reply is None:\n",
    "\tfor text in text_model_generator.generate(prompt=prompt, args=refresh_args, verbose=True):\n",
    "\t\tfoo = text.replace(prompt, \"\\n\")\n",
    "\t\tresult = capture_tag(foo, \"<|eor|>\")\n",
    "\t\tif result != None:\n",
    "\t\t\treply = result\n",
    "\t\t\tbreak\n",
    "print(reply)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!zip -r model.zip /content/finetune-gpt2xl/finetuned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!cp model.zip /content/drive/MyDrive/RawData/"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
