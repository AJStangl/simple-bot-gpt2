{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from shared_code.fine_tuning.tensor_encoding.tensor_encoding import TokenizerAdapter\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import TrainingArguments, Trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = \"yuri-bot\"\n",
    "\n",
    "parent_directory = \"/content/drive/MyDrive/RawData\"\n",
    "\n",
    "model_output_dir = f\"{parent_directory}/{model_name}\"\n",
    "\n",
    "tokenizer_path = f\"{model_output_dir}\"\n",
    "\n",
    "training_data_path = f\"/content/drive/MyDrive/RawData/training.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium',\n",
    "\t\t\t\t\t\t\t\t\t\t  bos_token='<|startoftext|>',\n",
    "\t\t\t\t\t\t\t\t\t\t  eos_token='<|endoftext|>',\n",
    "\t\t\t\t\t\t\t\t\t\t  pad_token='<|pad|>')\n",
    "\n",
    "tokenizer.save_pretrained(model_output_dir)\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-medium').cuda()\n",
    "\n",
    "tokenizer_adapter = TokenizerAdapter(tokenizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pandas.read_csv(training_data_path)\n",
    "\n",
    "conversations = list(df['TrainingString'])\n",
    "\n",
    "valid_lines = []\n",
    "for conversation in conversations:\n",
    "\tif tokenizer_adapter.token_length_appropriate(conversation):\n",
    "\t\tvalid_lines.append(conversation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from shared_code.fine_tuning.datasets.reddit_dataset import RedditDataset\n",
    "\n",
    "generator = torch.Generator()\n",
    "\n",
    "generator.manual_seed(0)\n",
    "\n",
    "print(f\":: Total Number Of Samples {len(valid_lines)}\")\n",
    "\n",
    "max_length = max([len(tokenizer.encode(prompt)) for prompt in valid_lines])\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "print(f\":: Max Length Of Sample {max_length}\")\n",
    "\n",
    "dataset = RedditDataset(valid_lines, tokenizer, max_length=max_length)\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "\n",
    "train_dataset, eval_dataset = random_split(dataset, [train_size, len(dataset) - train_size], generator=generator)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=model_output_dir)\n",
    "training_args.num_train_epochs = 5\n",
    "training_args.logging_steps = 100\n",
    "training_args.save_steps = 1000\n",
    "training_args.weight_decay = 0.05\n",
    "training_args.logging_dir = './logs'\n",
    "training_args.fp16 = True\n",
    "training_args.auto_find_batch_size = True\n",
    "training_args.gradient_accumulation_steps = 50\n",
    "training_args.learning_rate = 1e-4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer: Trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=eval_dataset,\n",
    "\t\t\t\t\t\t   data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t   'attention_mask': torch.stack([f[1] for f in data]),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t   'labels': torch.stack([f[0] for f in data])\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t   })"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "\n",
    "trainer.save_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "expecte_prompt = \"I love these bizarro eras of weirdness in AI development after it becomes possible to do but before it's perfected. Image synthesis itself was in the same place for several years back in the mid to late 2010s.\"\n",
    "\n",
    "prompt = \"<|soss r/dalle2|><|sot|>Detailed scientific diagram depicting the anatomy of a tomato, full colour, realistic<|sost|>https://i.imgur.com/7adBOXn.jpg<|sor u/AsterJ|>It's going to be sad day when it learns to properly spell.  I feel like this era is a fleeting moment in AI history.  We must cherish it.<|eor|><|sor\"\n",
    "\n",
    "generated = tokenizer(f\"<|startoftext|> {prompt}\", return_tensors=\"pt\")\n",
    "\n",
    "sample_outputs = model.generate(inputs=generated.input_ids.cuda(),\n",
    "\t\t\t\t\t\t\t\tattention_mask=generated['attention_mask'].cuda(),\n",
    "                                do_sample=True,\n",
    "                                top_k=40,\n",
    "\t\t\t\t\t\t\t\tmax_length=1024,\n",
    "                                top_p=0.8,\n",
    "                                temperature=0.8,\n",
    "                                num_return_sequences=10,\n",
    "\t\t\t\t\t\t\t\trepetition_penalty=1.08,\n",
    "                                stop_token='<|endoftext|>')\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    result = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "    print(\"{}: {}\".format(i, result.replace(prompt, \"\")))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
